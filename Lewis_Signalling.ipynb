{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lewis_Signalling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMahXhpXf04+x6s0UyabAcv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArghyaPal/Lewis_Signalling_RVED/blob/master/Lewis_Signalling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY7NqeS_6QK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b34e313-fccf-4852-8cd1-2018528d78b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeG8mYwl6vwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "feda4a39-15aa-4f12-b011-900c4be1e47f"
      },
      "source": [
        "%cd /content/drive/My Drive"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7EXDrgy6liy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! git clone https://github.com/chenzhaomin123/draw_pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXWEaGMh8DLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "449b37e3-97b8-4167-bf89-0923cd9a8e6d"
      },
      "source": [
        "cd Lewis_Signalling"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Lewis_Signalling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltaVrATmFPOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a341d53b-894c-4ffc-9456-442fd061f71c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'Lewis_Signalling': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXtg8Pld8JRc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff73840c-cf26-45fd-8c36-e53289166b3a"
      },
      "source": [
        "! python train.py"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.py:35: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
            "Epoch-0; Count-100; loss: 927.4809674072266;\n",
            "Epoch-0; Count-200; loss: 901.771015625;\n",
            "Epoch-0; Count-300; loss: 898.6575939941406;\n",
            "Epoch-0; Count-400; loss: 898.5250286865235;\n",
            "Epoch-0; Count-500; loss: 892.0511755371094;\n",
            "Epoch-0; Count-600; loss: 891.3379876708984;\n",
            "Epoch-0; Count-700; loss: 885.5721380615234;\n",
            "Epoch-0; Count-800; loss: 880.9260925292969;\n",
            "Epoch-0; Count-900; loss: 879.3516247558593;\n",
            "Epoch-1; Count-1000; loss: 875.6167816162109;\n",
            "/content/drive/My Drive/Lewis_Signalling/utility.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  return autograd.Variable(data,*args, **kwargs)\n",
            "image/count_1000_test_0.png\n",
            "image/count_1000_test_1.png\n",
            "image/count_1000_test_2.png\n",
            "image/count_1000_test_3.png\n",
            "image/count_1000_test_4.png\n",
            "image/count_1000_test_5.png\n",
            "image/count_1000_test_6.png\n",
            "image/count_1000_test_7.png\n",
            "image/count_1000_test_8.png\n",
            "image/count_1000_test_9.png\n",
            "image/count_1000_test_10.png\n",
            "image/count_1000_test_11.png\n",
            "image/count_1000_test_12.png\n",
            "image/count_1000_test_13.png\n",
            "image/count_1000_test_14.png\n",
            "image/count_1000_test_15.png\n",
            "image/count_1000_test_16.png\n",
            "image/count_1000_test_17.png\n",
            "image/count_1000_test_18.png\n",
            "/content/drive/My Drive/Lewis_Signalling/utility.py:66: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  plt.matshow(img, cmap=plt.cm.gray)\n",
            "image/count_1000_test_19.png\n",
            "Epoch-1; Count-1100; loss: 870.595961303711;\n",
            "Epoch-1; Count-1200; loss: 868.2192572021485;\n",
            "Epoch-1; Count-1300; loss: 865.0140167236328;\n",
            "Epoch-1; Count-1400; loss: 862.5739868164062;\n",
            "Epoch-1; Count-1500; loss: 859.7125085449219;\n",
            "Epoch-1; Count-1600; loss: 856.20896484375;\n",
            "Epoch-1; Count-1700; loss: 856.0655151367188;\n",
            "Epoch-1; Count-1800; loss: 851.68359375;\n",
            "Epoch-2; Count-1900; loss: 849.3047662353515;\n",
            "Epoch-2; Count-2000; loss: 847.9385711669922;\n",
            "image/count_2000_test_0.png\n",
            "image/count_2000_test_1.png\n",
            "image/count_2000_test_2.png\n",
            "image/count_2000_test_3.png\n",
            "image/count_2000_test_4.png\n",
            "image/count_2000_test_5.png\n",
            "image/count_2000_test_6.png\n",
            "image/count_2000_test_7.png\n",
            "image/count_2000_test_8.png\n",
            "image/count_2000_test_9.png\n",
            "image/count_2000_test_10.png\n",
            "image/count_2000_test_11.png\n",
            "image/count_2000_test_12.png\n",
            "image/count_2000_test_13.png\n",
            "image/count_2000_test_14.png\n",
            "image/count_2000_test_15.png\n",
            "image/count_2000_test_16.png\n",
            "image/count_2000_test_17.png\n",
            "image/count_2000_test_18.png\n",
            "image/count_2000_test_19.png\n",
            "Epoch-2; Count-2100; loss: 847.338232421875;\n",
            "Epoch-2; Count-2200; loss: 845.5244268798829;\n",
            "Epoch-2; Count-2300; loss: 844.8343341064453;\n",
            "Epoch-2; Count-2400; loss: 842.5977722167969;\n",
            "Epoch-2; Count-2500; loss: 843.2045141601562;\n",
            "Epoch-2; Count-2600; loss: 841.0527716064453;\n",
            "Epoch-2; Count-2700; loss: 840.4636224365235;\n",
            "Epoch-2; Count-2800; loss: 838.5014233398438;\n",
            "Epoch-3; Count-2900; loss: 838.0421862792969;\n",
            "Epoch-3; Count-3000; loss: 837.5359399414062;\n",
            "image/count_3000_test_0.png\n",
            "image/count_3000_test_1.png\n",
            "image/count_3000_test_2.png\n",
            "image/count_3000_test_3.png\n",
            "image/count_3000_test_4.png\n",
            "image/count_3000_test_5.png\n",
            "image/count_3000_test_6.png\n",
            "image/count_3000_test_7.png\n",
            "image/count_3000_test_8.png\n",
            "image/count_3000_test_9.png\n",
            "image/count_3000_test_10.png\n",
            "image/count_3000_test_11.png\n",
            "image/count_3000_test_12.png\n",
            "image/count_3000_test_13.png\n",
            "image/count_3000_test_14.png\n",
            "image/count_3000_test_15.png\n",
            "image/count_3000_test_16.png\n",
            "image/count_3000_test_17.png\n",
            "image/count_3000_test_18.png\n",
            "image/count_3000_test_19.png\n",
            "Epoch-3; Count-3100; loss: 837.3460375976563;\n",
            "Epoch-3; Count-3200; loss: 835.9327227783203;\n",
            "Epoch-3; Count-3300; loss: 835.5464477539062;\n",
            "Epoch-3; Count-3400; loss: 834.94994140625;\n",
            "Epoch-3; Count-3500; loss: 834.7372894287109;\n",
            "Epoch-3; Count-3600; loss: 834.7552319335938;\n",
            "Epoch-3; Count-3700; loss: 832.3553112792969;\n",
            "Epoch-4; Count-3800; loss: 831.6505352783203;\n",
            "Epoch-4; Count-3900; loss: 831.0160498046876;\n",
            "Epoch-4; Count-4000; loss: 830.5375103759766;\n",
            "image/count_4000_test_0.png\n",
            "image/count_4000_test_1.png\n",
            "image/count_4000_test_2.png\n",
            "image/count_4000_test_3.png\n",
            "image/count_4000_test_4.png\n",
            "image/count_4000_test_5.png\n",
            "image/count_4000_test_6.png\n",
            "image/count_4000_test_7.png\n",
            "image/count_4000_test_8.png\n",
            "image/count_4000_test_9.png\n",
            "image/count_4000_test_10.png\n",
            "image/count_4000_test_11.png\n",
            "image/count_4000_test_12.png\n",
            "image/count_4000_test_13.png\n",
            "image/count_4000_test_14.png\n",
            "image/count_4000_test_15.png\n",
            "image/count_4000_test_16.png\n",
            "image/count_4000_test_17.png\n",
            "image/count_4000_test_18.png\n",
            "image/count_4000_test_19.png\n",
            "Epoch-4; Count-4100; loss: 830.8536956787109;\n",
            "Epoch-4; Count-4200; loss: 829.0645782470704;\n",
            "Epoch-4; Count-4300; loss: 830.0665118408203;\n",
            "Epoch-4; Count-4400; loss: 829.0339483642579;\n",
            "Epoch-4; Count-4500; loss: 828.3902362060547;\n",
            "Epoch-4; Count-4600; loss: 828.2123541259766;\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 62, in <module>\n",
            "  File \"train.py\", line 32, in train\n",
            "    loss = model.loss(data)\n",
            "  File \"/content/drive/My Drive/Lewis_Signalling/draw_model.py\", line 123, in loss\n",
            "    Lx = self.forward(x)\n",
            "  File \"/content/drive/My Drive/Lewis_Signalling/draw_model.py\", line 93, in forward\n",
            "    r_t = self.read(x,x_hat,h_enc_prev)\n",
            "  File \"/content/drive/My Drive/Lewis_Signalling/draw_model.py\", line 166, in read\n",
            "    (Fx,Fy),gamma = self.attn_window(h_enc_prev)\n",
            "  File \"/content/drive/My Drive/Lewis_Signalling/draw_model.py\", line 155, in attn_window\n",
            "    gx = (self.A + 1) / 2 * (gx_ + 1)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}